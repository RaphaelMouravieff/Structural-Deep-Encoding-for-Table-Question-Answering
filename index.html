<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
    <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="We propose Structural Deep Encoding, a novel approach for Table Question Answering leveraging sparse attention and symbolic execution.">
  <meta name="keywords" content="Table Question Answering, Deep Learning, NLP, Natural Language Processing, SQL Supervision, Sparse Attention, Structural Encoding, ACL 2025, Semantic Parsing">
  <meta name="author" content="Raphaël Mouravieff, Benjamin Piwowarski, Sylvain Lamprier">

  <meta name="robots" content="index, follow">  
  <meta property="og:title" content="Structural Deep Encoding for Table Question Answering"/>
  <meta property="og:description" content="We introduce Structural Deep Encoding: a novel method combining symbolic structure and deep models for Table QA. ACL 2025."/>
  <meta property="og:type" content="website">
  <meta property="og:url" content="https://raphaelmouravieff.github.io/Structural-Deep-Encoding-for-Table-Question-Answering/"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/images/structural-deep-encoding-overview.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>



  <meta name="twitter:card" content="summary_large_image">
  <meta name="twitter:title" content="Structural Deep Encoding for Table Question Answering">
  <meta name="twitter:description" content="We introduce Structural Deep Encoding: a novel method combining symbolic structure and deep models for Table QA. ACL 2025.">
  <meta name="twitter:image" content="https://raphaelmouravieff.github.io/Structural-Deep-Encoding-for-Table-Question-Answering/static/images/structural-deep-encoding-overview.png">


  <!-- Keywords for your paper to be indexed by-->
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>Structural Deep Encoding for Table Question Answering</title>
  <link rel="icon" type="image/x-icon" href="static/images/table.ico">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">Structural Deep Encoding for Table Question Answering</h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
                <span class="author-block">
                  <a href="https://scholar.google.com/citations?user=PtV524cAAAAJ&hl=fr" target="_blank">Raphaël Mouravieff</a><sup></sup>,</span>
              <span class="author-block">
                  <a href="https://www.piwowarski.fr/" target="_blank">Benjamin Piwowarski</a><sup></sup>,</span>
                <span class="author-block">
                   <a href="https://scholar.google.fr/citations?user=NuGN8SUAAAAJ&hl=en" target="_blank">Sylvain Lamprier</a><sup></sup>,</span>
                </span>
                </div>

                  <div class="is-size-5 publication-authors">
                    <span class="author-block">ISIR / MLIA<br>ACL 2025</span>
                  </div>

                  <div class="column has-text-centered">
                    <div class="publication-links">
                      
                  <!-- ACL PDF link -->
                  <span class="link-block">
                    <a href="" target="_blank"
                       class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="fas fa-file-pdf"></i>
                      </span>
                      <span>Paper</span>
                    </a>
                  </span>

                  <!-- Github link -->
                  <span class="link-block">
                    <a href="https://github.com/RaphaelMouravieff/TabStruct" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>

                <!-- ArXiv abstract Link -->
                <span class="link-block">
                  <a href="https://arxiv.org/pdf/2503.01457" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<!-- Teaser image -->
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <img src="static/images/structural-deep-encoding-overview.png" alt="Table QA ACL Project" height="100%" width="100%">
      <h2 class="subtitle has-text-centered">
         Overview of the encoding pipeline (blue) along with the different steps where table-specific information can be injected (red)
      </h2>
    </div>
  </div>
</section>
<!-- End teaser image -->

<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Although Transformers-based architectures excel at processing textual information, their naive adaptation for tabular data often involves flattening the table structure. This simplification can lead to the loss of essential interdependencies between rows, columns, and cells, while also posing scalability challenges for large tables. To address these issues, prior works have explored special tokens, structured embeddings, and sparse attention patterns. In this paper, we conduct a comprehensive analysis of tabular encoding techniques, which highlights the crucial role of attention sparsity in preserving structural information of tables. We also introduce a set of novel sparse attention mask designs for tabular data, that not only enhance computational efficiency but also preserve structural integrity, leading to better overall performance. 
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->

  




<!-- Paper poster -->
<section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <h2 class="title">Poster</h2>

      <iframe  src="static/pdfs/Poster_Structural_encoding.pdf" width="100%" height="550">
          </iframe>
        
      </div>
    </div>
  </section>
<!--End paper poster -->


<!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>@inproceedings{mouravieff-etal-2024-learning,
    title = "Learning Relational Decomposition of Queries for Question Answering from Tables",
    author = {Mouravieff, Rapha{\"e}l  and
      Piwowarski, Benjamin  and
      Lamprier, Sylvain},
    editor = "Ku, Lun-Wei  and
      Martins, Andre  and
      Srikumar, Vivek",
    booktitle = "Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = aug,
    year = "2024",
    address = "Bangkok, Thailand",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.acl-long.564",
    doi = "10.18653/v1/2024.acl-long.564",
    pages = "10471--10485",
    abstract = "Table Question-Answering involves both understanding the natural language query and grounding it in the context of the input table to extract relevant information. In this context, many methods have highlighted the benefits of intermediate pre-training using SQL queries. However, while most approaches aim at generating final answers directly from inputs, we claim that there is better to do with SQL queries during training.By learning to imitate a restricted subset of SQL-like algebraic operations, we demonstrate that their execution flow provides intermediate supervision steps that allow for increased generalization and structural reasoning compared to classical approaches. Our method, bridges the gap between semantic parsing and direct answering methods, offering valuable insights into which types of operations should be predicted by a generative architecture and which should be executed by an external algorithm. Our code can be found at https://github.com/RaphaelMouravieff/Partial-Exec.",
}
</code></pre>
    </div>
</section>
<!--End BibTex citation -->


  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
            You are free to borrow the source code of this website, we just ask that you link back to this page in the footer. <br> This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
